# csv mappings
csvSchema {
  rowSize = 13
	x { type = double, index = 10 }
  y { type = double, index = 11 }
  time { type = date, index = 5 }
}

# pass-through config for spark (see http://spark.apache.org/docs/latest/configuration.html)
spark {
  master = "local"
  app.name = test
}

# pass-through config for spark-csv data loader (see https://github.com/databricks/spark-csv)
sparkCsv {
  delimiter = ","
  header = "true"
  dateFormat = "yyyy-MM-dd HH:mm:ss.S"
}

# general tiling job config
tiling {
  levels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]
  bins = 4
  source = "src/test/resources/taxi_one_day.csv"
}

# temporal heatmap config
xyTimeHeatmap {
	xColumn = x
	yColumn = y
  projection = mercator
  timeColumn = time
  # start time, time step size, number of steps
  min = 1371009600000
  step = 86400000
  count = 1
}

# local file output config
fileOutput {
  dest = "build/tmp/test_file_output"
  layer = test_heatmap
}



