# csv mappings
csvSchema {
  rowSize = 7
  x { type = double, index = 0 }
  y { type = double, index = 1 }
  text { type = string, index = 2}
}

# pass-through config for spark (see http://spark.apache.org/docs/latest/configuration.html)
spark {
  master = "local"
  app.name = test
}

# pass-through config for spark-csv data loader (see https://github.com/databricks/spark-csv)
sparkCsv {
  delimiter = "\t"
  header = "false"
}

# general tiling job config
tiling {
  levels = [0,1,2]
  bins = 1
  source = "src/test/resources/XYTopicsJobTest/topic-test-detailed.csv"
}

# temporal heatmap config
xyTopics {
  xColumn = x
  yColumn = y
  projection = mercator
  textColumn = text
  valueColumn = value
  topicLimit = 10
  terms = "src/test/resources/terms.csv" //expected level 2 output in 7th column and expected bin coord for level 2 tiles in 8th column
}

# local file output config
fileOutput {
  dest = "build/tmp/test_file_output"
  layer = test_topics
}



