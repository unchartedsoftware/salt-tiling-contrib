# pass-through config for spark csv data loader - see https://spark.apache.org/docs/2.1.0/api/scala/index.html#org.apache.spark.sql.DataFrameReader under the csv method for full set of args.
# for full set of options
sparkCsv {
  sep = ","
  header = false
  mode = DROPMALFORMED
}

# maps indexed columns from input CSV to named + typed columns in
# Dataframe
csvSchema {
  rowSize = 14
  lon { type = double, index = 10 }
  lat { type = double, index = 11 }
}

# spark config - anything in spark block is passed through as a property to the spark context
# see http://spark.apache.org/docs/latest/configuration.html
spark {
  master = "local[*]"
  app.name = salt-geo-heatmap-test
}

# general tiling job config
tiling {
  levels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]
  bins = 256
  source = ../data/taxi_micro.csv
}

# heatmap config
xyHeatmap {
  projection = mercator
  xColumn = lon
  yColumn = lat
}

# file output config
fileOutput {
  dest = ../tiles
  layer = geo_heatmap
}
