# map csv columns
csvSchema {
  rowSize = 13
  lon { type = double, index = 10 }
  lat { type = double, index = 11 }
  time { type = date, index = 5 }
}
# spark config - anything in spark block is passed through as a property to the spark context
spark {
  master = yarn-client
  app.name = salt-heatmap-test
}
# general tiling job config
tiling {
  levels = [0,1,2]
  bins = 256
  source = "hdfs://uscc0-master0.uncharted.software/xdata/data/nyc_taxi/trip"
}
# temporal heatmap config
xyTimeHeatmap {
  projection = mercator
  xColumn = lat
  yColumn = lon
  timeColumn = time
  min = 1357016400000
  step = 2628000000
  count = 12
}
# Amazon S3 output config
s3Output {
  bucket = xdata-tiles
  layer = taxi_heatmap_1_month
  awsAccessKey = ${AWS_ACCESS_KEY} 
  awsSecretKey = ${AWS_SECRET_KEY}
}
# pass-through config for spark-csv data loader (see https://github.com/databricks/spark-csv)
sparkCsv {
  delimiter = ","
  header = true
  mode = DROPMALFORMED
}
